{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Model (i.e. the MVP) Using text articles to predict sentiment\n",
    "\n",
    "- this was my MVP, which was simply to train a model to predict sentiment for each article\n",
    "- Target was the sentiment score provided by GDELT\n",
    "- Each row represents a single article\n",
    "- I achieved reasonable results with very little hyperparameter tuning, which gave me the confidence to move on to exploring external targets like sentiment and Google Trends data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import SparsePCA\n",
    "import spacy\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in article data\n",
    "text_tokens = pd.read_csv('/floyd/home/Capstone/cap_notebooks/data/master_data_set/text_with_tokens_52k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-spacy tokenizer\n",
    "#text cleaning helper function\n",
    "def cleaning_tokens(list_of_tokens):\n",
    "    #initial_list = []\n",
    "    #grabs tokens and removes '[]', splits on comma and returns list\n",
    "    initial_list = list_of_tokens.strip('[').strip(']').split(',')\n",
    "    clean_list = []\n",
    "    #loops through new list and removes whitespaces and extra \"'\"\n",
    "    for token in initial_list:\n",
    "        clean_list.append(token.strip().strip(\"'\"))\n",
    "\n",
    "    return clean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gkgcode</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>tone</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>text</th>\n",
       "      <th>date_str</th>\n",
       "      <th>Tone_only</th>\n",
       "      <th>polarity</th>\n",
       "      <th>text_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20150302100000-674</td>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>http://www.nationalreview.com/article/414611/a...</td>\n",
       "      <td>0.350631136044881,2.73492286115007,2.384291725...</td>\n",
       "      <td>Is America a ‘Clean Energy’ Laggard?</td>\n",
       "      <td>['Robert Bryce', 'Victor Davis Hanson', 'Isaac...</td>\n",
       "      <td>2015-03-02 04:00:00+00:00</td>\n",
       "      <td>The answer is not only “No,” but a resounding ...</td>\n",
       "      <td>20150302</td>\n",
       "      <td>0.350631</td>\n",
       "      <td>5.119215</td>\n",
       "      <td>['answer', 'resounding', 'myriad', 'claim', 'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>20150302153000-229</td>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>http://www.latimes.com/business/hiltzik/la-fi-...</td>\n",
       "      <td>-0.952380952380953,3.49206349206349,4.44444444...</td>\n",
       "      <td>Watch ‘Meet the Press’ treat climate change as...</td>\n",
       "      <td>['Business Columnist', 'Los Angeles Times Colu...</td>\n",
       "      <td>2015-03-01 00:00:00</td>\n",
       "      <td>As you may have heard, Sen. James Inhofe (R-Ok...</td>\n",
       "      <td>20150302</td>\n",
       "      <td>-0.952381</td>\n",
       "      <td>7.936508</td>\n",
       "      <td>['hear', 'sen.', 'james', 'inhofe', 'r', 'okla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>20150302163000-237</td>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>http://www.usatoday.com/story/news/nation-now/...</td>\n",
       "      <td>0,1.8140589569161,1.8140589569161,3.6281179138...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>2015-03-02 00:00:00</td>\n",
       "      <td>Mary Bowerman  USA TODAY Network  Visitors sho...</td>\n",
       "      <td>20150302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.628118</td>\n",
       "      <td>['mary', 'bowerman', 'usa', 'today', 'network'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20150302180000-1352</td>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>http://www.nytimes.com/2015/03/03/business/int...</td>\n",
       "      <td>-1.14754098360656,1.80327868852459,2.950819672...</td>\n",
       "      <td>Russian Energy Deal Comes at Contentious Time</td>\n",
       "      <td>['Stanley Reed']</td>\n",
       "      <td>2015-03-03 00:00:00</td>\n",
       "      <td>But Mr. Fridman has a business track record th...</td>\n",
       "      <td>20150302</td>\n",
       "      <td>-1.147541</td>\n",
       "      <td>4.754098</td>\n",
       "      <td>['mr.', 'fridman', 'business', 'track', 'recor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>20150302203000-163</td>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>http://www.cbsnews.com/news/did-climate-change...</td>\n",
       "      <td>-8.0545229244114,0.371747211895911,8.426270136...</td>\n",
       "      <td>Did climate change cause the Syrian civil war?</td>\n",
       "      <td>['Michael Casey', 'Michael Casey Covers The En...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Climate change sparked a historic drought in S...</td>\n",
       "      <td>20150302</td>\n",
       "      <td>-8.054523</td>\n",
       "      <td>8.798017</td>\n",
       "      <td>['climate', 'change', 'spark', 'historic', 'dr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              gkgcode        date  \\\n",
       "0           0   20150302100000-674  2015-03-02   \n",
       "1           3   20150302153000-229  2015-03-02   \n",
       "2           6   20150302163000-237  2015-03-02   \n",
       "3           4  20150302180000-1352  2015-03-02   \n",
       "4           2   20150302203000-163  2015-03-02   \n",
       "\n",
       "                                                link  \\\n",
       "0  http://www.nationalreview.com/article/414611/a...   \n",
       "1  http://www.latimes.com/business/hiltzik/la-fi-...   \n",
       "2  http://www.usatoday.com/story/news/nation-now/...   \n",
       "3  http://www.nytimes.com/2015/03/03/business/int...   \n",
       "4  http://www.cbsnews.com/news/did-climate-change...   \n",
       "\n",
       "                                                tone  \\\n",
       "0  0.350631136044881,2.73492286115007,2.384291725...   \n",
       "1  -0.952380952380953,3.49206349206349,4.44444444...   \n",
       "2  0,1.8140589569161,1.8140589569161,3.6281179138...   \n",
       "3  -1.14754098360656,1.80327868852459,2.950819672...   \n",
       "4  -8.0545229244114,0.371747211895911,8.426270136...   \n",
       "\n",
       "                                               title  \\\n",
       "0               Is America a ‘Clean Energy’ Laggard?   \n",
       "1  Watch ‘Meet the Press’ treat climate change as...   \n",
       "2                                                NaN   \n",
       "3      Russian Energy Deal Comes at Contentious Time   \n",
       "4     Did climate change cause the Syrian civil war?   \n",
       "\n",
       "                                             authors  \\\n",
       "0  ['Robert Bryce', 'Victor Davis Hanson', 'Isaac...   \n",
       "1  ['Business Columnist', 'Los Angeles Times Colu...   \n",
       "2                                                 []   \n",
       "3                                   ['Stanley Reed']   \n",
       "4  ['Michael Casey', 'Michael Casey Covers The En...   \n",
       "\n",
       "                    pub_date  \\\n",
       "0  2015-03-02 04:00:00+00:00   \n",
       "1        2015-03-01 00:00:00   \n",
       "2        2015-03-02 00:00:00   \n",
       "3        2015-03-03 00:00:00   \n",
       "4                        NaN   \n",
       "\n",
       "                                                text  date_str  Tone_only  \\\n",
       "0  The answer is not only “No,” but a resounding ...  20150302   0.350631   \n",
       "1  As you may have heard, Sen. James Inhofe (R-Ok...  20150302  -0.952381   \n",
       "2  Mary Bowerman  USA TODAY Network  Visitors sho...  20150302   0.000000   \n",
       "3  But Mr. Fridman has a business track record th...  20150302  -1.147541   \n",
       "4  Climate change sparked a historic drought in S...  20150302  -8.054523   \n",
       "\n",
       "   polarity                                         text_token  \n",
       "0  5.119215  ['answer', 'resounding', 'myriad', 'claim', 'e...  \n",
       "1  7.936508  ['hear', 'sen.', 'james', 'inhofe', 'r', 'okla...  \n",
       "2  3.628118  ['mary', 'bowerman', 'usa', 'today', 'network'...  \n",
       "3  4.754098  ['mr.', 'fridman', 'business', 'track', 'recor...  \n",
       "4  8.798017  ['climate', 'change', 'spark', 'historic', 'dr...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reviewing data\n",
    "text_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.774077419672286"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating mean tone\n",
    "text_tokens['Tone_only'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binarizing tone\n",
    "text_tokens['binary_tone'] = np.where(text_tokens['Tone_only']>=-1.6, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26431"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking balance of dataset target\n",
    "text_tokens['binary_tone'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52758"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comparing above cell to length of dataset\n",
    "len(text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting X and y\n",
    "X = text_tokens['text_token']\n",
    "y = text_tokens['binary_tone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train, X_test, y_train,y_test = train_test_split(X,y, test_size=.3, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words, Log Reg, Tone Target\n",
    "\n",
    "- Applies CountVectorizer and Logistic Regression\n",
    "- Target is article tone score from Gdelt\n",
    "- train acc: 81 percent\n",
    "- test acc: 79 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating Count Vectorizer\n",
    "bagofwords = CountVectorizer(min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting bagofwords\n",
    "bagofwords.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming X_train, X_test\n",
    "X_train_transformed = bagofwords.transform(X_train)\n",
    "X_test_transformed = bagofwords.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting log reg model\n",
    "model = LogisticRegression(C=.01, solver='saga')\n",
    "model.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7988375031589589"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8139994584348768"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#scoring model\n",
    "display(model.score(X_test_transformed, y_test))\n",
    "display(model.score(X_train_transformed, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF, Log Reg, Tone Target\n",
    "\n",
    "- Applies TFIDF Vectorizer and Logistic Regression\n",
    "- Target is article tone score from Gdelt\n",
    "- train acc: 89 percent\n",
    "- test acc: 84 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split done - X_train shape: (36930,), X_test shape: (15828,), y_train shape: (36930,), y_test shape: (15828,)\n",
      "vectorizer done\n",
      "beginng vectorizer fitting\n",
      "vectorizer fitting complete\n",
      "beginning transformation\n",
      "X_train transformed\n",
      "X_test_transformed\n",
      "creating model\n",
      "model completed\n",
      "fitting model\n",
      "model fitted\n",
      "scoring training data\n",
      "scoring test data\n",
      "Training score: 0.8919848361765502\n",
      "Test score: 0.846095526914329\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=.3, stratify=y)\n",
    "print(f'Split done - X_train shape: {X_train.shape}, X_test shape: {X_test.shape}, y_train shape: {y_train.shape}, y_test shape: {y_test.shape}')\n",
    "\n",
    "#create vectorizer\n",
    "bagofwords = TfidfVectorizer(min_df=5)\n",
    "print('vectorizer done')\n",
    "\n",
    "#fit vectorizer\n",
    "print('beginng vectorizer fitting')\n",
    "bagofwords.fit(X_train)\n",
    "print('vectorizer fitting complete')\n",
    "\n",
    "\n",
    "#transform X_train\n",
    "print('beginning transformation')\n",
    "X_train_transformed = bagofwords.transform(X_train)\n",
    "print('X_train transformed')\n",
    "\n",
    "#transform X_test\n",
    "X_test_transformed = bagofwords.transform(X_test)\n",
    "print('X_test_transformed')\n",
    "\n",
    "#create model\n",
    "print('creating model')\n",
    "model = LogisticRegression(C=1, solver='liblinear')\n",
    "print('model completed')\n",
    "\n",
    "\n",
    "#fit model\n",
    "print('fitting model')\n",
    "model.fit(X_train_transformed, y_train)\n",
    "print('model fitted')\n",
    "\n",
    "#score training set \n",
    "print('scoring training data')\n",
    "train_score = model.score(X_train_transformed, y_train)\n",
    "\n",
    "#score test set\n",
    "print('scoring test data')\n",
    "test_score = model.score(X_test_transformed, y_test)\n",
    "\n",
    "print(f'Training score: {train_score}')\n",
    "print(f'Test score: {test_score}')\n",
    "#return (bagofwords, model, X_train_transformed, X_test_transformed, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF with N-Grams, Log Reg, Tone Target with C = .01\n",
    "\n",
    "- Applies TFIDF Vectorizer, bi-grams, and Logistic Regression\n",
    "- Target is article tone score from Gdelt\n",
    "- train acc: 74 percent\n",
    "- test acc: 73 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split done - X_train shape: (36930,), X_test shape: (15828,), y_train shape: (36930,), y_test shape: (15828,)\n",
      "vectorizer done\n",
      "beginng vectorizer fitting\n",
      "vectorizer fitting complete\n",
      "beginning transformation\n",
      "X_train transformed\n",
      "X_test_transformed\n",
      "creating model\n",
      "model completed\n",
      "fitting model\n",
      "model fitted\n",
      "scoring training data\n",
      "scoring test data\n",
      "Training score: 0.7423503926347144\n",
      "Test score: 0.7323730098559514\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=.3, stratify=y)\n",
    "print(f'Split done - X_train shape: {X_train.shape}, X_test shape: {X_test.shape}, y_train shape: {y_train.shape}, y_test shape: {y_test.shape}')\n",
    "\n",
    "#create vectorizer\n",
    "bagofwords = TfidfVectorizer(min_df=5, ngram_range=(1,2))\n",
    "print('vectorizer done')\n",
    "\n",
    "#fit vectorizer\n",
    "print('beginng vectorizer fitting')\n",
    "bagofwords.fit(X_train)\n",
    "print('vectorizer fitting complete')\n",
    "\n",
    "\n",
    "#transform X_train\n",
    "print('beginning transformation')\n",
    "X_train_transformed = bagofwords.transform(X_train)\n",
    "print('X_train transformed')\n",
    "\n",
    "#transform X_test\n",
    "X_test_transformed = bagofwords.transform(X_test)\n",
    "print('X_test_transformed')\n",
    "\n",
    "#create model\n",
    "print('creating model')\n",
    "model = LogisticRegression(C=.01, solver='saga')\n",
    "print('model completed')\n",
    "\n",
    "\n",
    "#fit model\n",
    "print('fitting model')\n",
    "model.fit(X_train_transformed, y_train)\n",
    "print('model fitted')\n",
    "\n",
    "#score training set \n",
    "print('scoring training data')\n",
    "train_score = model.score(X_train_transformed, y_train)\n",
    "\n",
    "#score test set\n",
    "print('scoring test data')\n",
    "test_score = model.score(X_test_transformed, y_test)\n",
    "\n",
    "print(f'Training score: {train_score}')\n",
    "print(f'Test score: {test_score}')\n",
    "#return (bagofwords, model, X_train_transformed, X_test_transformed, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF with N-Grams, Log Reg, Tone Target with C = .1\n",
    "\n",
    "- Applies TFIDF Vectorizer, bi-grams, and Logistic Regression\n",
    "- Target is article tone score from Gdelt\n",
    "- reduced penalty\n",
    "- train acc: 81 percent\n",
    "- test acc: 78 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split done - X_train shape: (36930,), X_test shape: (15828,), y_train shape: (36930,), y_test shape: (15828,)\n",
      "vectorizer done\n",
      "beginng vectorizer fitting\n",
      "vectorizer fitting complete\n",
      "beginning transformation\n",
      "X_train transformed\n",
      "X_test_transformed\n",
      "creating model\n",
      "model completed\n",
      "fitting model\n",
      "model fitted\n",
      "scoring training data\n",
      "scoring test data\n",
      "Training score: 0.8124830760898998\n",
      "Test score: 0.7849380844073793\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=.3, stratify=y)\n",
    "print(f'Split done - X_train shape: {X_train.shape}, X_test shape: {X_test.shape}, y_train shape: {y_train.shape}, y_test shape: {y_test.shape}')\n",
    "\n",
    "#create vectorizer\n",
    "bagofwords = TfidfVectorizer(min_df=5, ngram_range=(1,2))\n",
    "print('vectorizer done')\n",
    "\n",
    "#fit vectorizer\n",
    "print('beginng vectorizer fitting')\n",
    "bagofwords.fit(X_train)\n",
    "print('vectorizer fitting complete')\n",
    "\n",
    "\n",
    "#transform X_train\n",
    "print('beginning transformation')\n",
    "X_train_transformed = bagofwords.transform(X_train)\n",
    "print('X_train transformed')\n",
    "\n",
    "#transform X_test\n",
    "X_test_transformed = bagofwords.transform(X_test)\n",
    "print('X_test_transformed')\n",
    "\n",
    "#create model\n",
    "print('creating model')\n",
    "model = LogisticRegression(C=.1, solver='saga')\n",
    "print('model completed')\n",
    "\n",
    "\n",
    "#fit model\n",
    "print('fitting model')\n",
    "model.fit(X_train_transformed, y_train)\n",
    "print('model fitted')\n",
    "\n",
    "#score training set \n",
    "print('scoring training data')\n",
    "train_score = model.score(X_train_transformed, y_train)\n",
    "\n",
    "#score test set\n",
    "print('scoring test data')\n",
    "test_score = model.score(X_test_transformed, y_test)\n",
    "\n",
    "print(f'Training score: {train_score}')\n",
    "print(f'Test score: {test_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#next step, build a grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction\n",
    "\n",
    "- Tried dimensionality reduction\n",
    "- I seemed to have failed to save the results, but I did make a note that it took a long time and did not improve on previous models, so abandoned this approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this takes a long time and doesnt yield great results\n",
    "tsvd = TruncatedSVD(n_components=1000)\n",
    "X_train_transformed_sparse_tsvd = tsvd.fit(X_train_transformed).transform(X_train_transformed)\n",
    "X_test_transformed_sparse_tsvd = tsvd.transform(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split done - X_train shape: (36930,), X_test shape: (15828,), y_train shape: (36930,), y_test shape: (15828,)\n",
      "vectorizer done\n",
      "beginng vectorizer fitting\n",
      "vectorizer fitting complete\n",
      "beginning transformation\n",
      "X_train transformed\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=.3, stratify=y)\n",
    "print(f'Split done - X_train shape: {X_train.shape}, X_test shape: {X_test.shape}, y_train shape: {y_train.shape}, y_test shape: {y_test.shape}')\n",
    "\n",
    "#create vectorizer\n",
    "bagofwords = TfidfVectorizer(min_df=5)\n",
    "print('vectorizer done')\n",
    "\n",
    "#fit vectorizer\n",
    "print('beginng vectorizer fitting')\n",
    "bagofwords.fit(X_train)\n",
    "print('vectorizer fitting complete')\n",
    "\n",
    "\n",
    "#transform X_train\n",
    "print('beginning transformation')\n",
    "X_train_transformed = bagofwords.transform(X_train)\n",
    "print('X_train transformed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "neptune": {
   "notebookId": "5c999c41-6016-4db6-96fe-d646879a7513"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
