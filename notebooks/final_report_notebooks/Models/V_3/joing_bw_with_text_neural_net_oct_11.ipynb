{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net Regression and Neural Net with TF-IDF\n",
    "\n",
    "- V3_Data: Target: Brandwatch Sentiment, Row = Daily articles, Time: 2018 - 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "#import statements\n",
    "from tensorflow.keras import regularizers\n",
    "import scipy\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "!pip install tensorflow-hub\n",
    "#!pip install tensorflow-datasets\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data and Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in v3 text data\n",
    "text = pd.read_csv('/floyd/home/Capstone/cap_notebooks/data/master_data_set/text_with_tokens_52k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter for date and tokens\n",
    "text = text[['date', 'text_token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>['answer', 'resounding', 'myriad', 'claim', 'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>['hear', 'sen.', 'james', 'inhofe', 'r', 'okla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>['mary', 'bowerman', 'usa', 'today', 'network'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>['mr.', 'fridman', 'business', 'track', 'recor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>['climate', 'change', 'spark', 'historic', 'dr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                         text_token\n",
       "0  2015-03-02  ['answer', 'resounding', 'myriad', 'claim', 'e...\n",
       "1  2015-03-02  ['hear', 'sen.', 'james', 'inhofe', 'r', 'okla...\n",
       "2  2015-03-02  ['mary', 'bowerman', 'usa', 'today', 'network'...\n",
       "3  2015-03-02  ['mr.', 'fridman', 'business', 'track', 'recor...\n",
       "4  2015-03-02  ['climate', 'change', 'spark', 'historic', 'dr..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date to datetime object\n",
    "text['date'] = pd.to_datetime(text['date'])\n",
    "\n",
    "#create day groupby object\n",
    "grouped_text = text.groupby([text['date'].dt.year, text['date'].dt.month, text['date'].dt.day])\n",
    "\n",
    "#aggregating tokens by day\n",
    "text_day_grouped = grouped_text['text_token'].agg(lambda column: \"\".join(column))\n",
    "\n",
    "#set as df\n",
    "text_day_grouped = pd.DataFrame(text_day_grouped)\n",
    "\n",
    "#rename index\n",
    "text_day_grouped = text_day_grouped.rename_axis(index=['year', 'month', 'day'])\n",
    "\n",
    "#reset_index\n",
    "text_day_grouped = text_day_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>text_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>['answer', 'resounding', 'myriad', 'claim', 'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>['scientist', 'center', 'controversy', 'fossil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>['scientist', 'step', 'closer', 'understand', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>['high', 'blessed', 'relief', 'finally', 'pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>['california', 'lead', 'nation', 'take', 'acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>['calistoga', 'california', 'california', 'fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>['خطر', 'الإنفلونزا', 'قد', 'يكون', 'أقل', 'هذ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>['london', 'thomson', 'reuters', 'foundation',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>['1', 'president', 'trump', 'americans', 'afra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>['november', 'presidential', 'election', 'week...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1862 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  month  day                                         text_token\n",
       "0     2015      3    2  ['answer', 'resounding', 'myriad', 'claim', 'e...\n",
       "1     2015      3    3  ['scientist', 'center', 'controversy', 'fossil...\n",
       "2     2015      3    4  ['scientist', 'step', 'closer', 'understand', ...\n",
       "3     2015      3    5  ['high', 'blessed', 'relief', 'finally', 'pres...\n",
       "4     2015      3    6  ['california', 'lead', 'nation', 'take', 'acti...\n",
       "...    ...    ...  ...                                                ...\n",
       "1857  2020     10    3  ['calistoga', 'california', 'california', 'fir...\n",
       "1858  2020     10    4  ['خطر', 'الإنفلونزا', 'قد', 'يكون', 'أقل', 'هذ...\n",
       "1859  2020     10    5  ['london', 'thomson', 'reuters', 'foundation',...\n",
       "1860  2020     10    6  ['1', 'president', 'trump', 'americans', 'afra...\n",
       "1861  2020     10    7  ['november', 'presidential', 'election', 'week...\n",
       "\n",
       "[1862 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_day_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates grouping column\n",
    "text_day_grouped['date_grouped'] = pd.to_datetime(text_day_grouped[['year', 'month', 'day']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in brandwatch sentiment data\n",
    "sentiment = pd.read_csv('/floyd/home/Capstone/cap_notebooks/data/brandwatch/bw_sentiment_emotion_day/bw_sentiment_2018-2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>days</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>-1.119873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-10-06</td>\n",
       "      <td>-0.847089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-10-07</td>\n",
       "      <td>-1.485399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>-0.894346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-10-09</td>\n",
       "      <td>-0.762045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         days  sentiment\n",
       "0           1  2018-10-05   -1.119873\n",
       "1           2  2018-10-06   -0.847089\n",
       "2           3  2018-10-07   -1.485399\n",
       "3           4  2018-10-08   -0.894346\n",
       "4           5  2018-10-09   -0.762045"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data\n",
    "sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop extra columns\n",
    "sentiment.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>-1.119873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-10-06</td>\n",
       "      <td>-0.847089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-10-07</td>\n",
       "      <td>-1.485399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>-0.894346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-10-09</td>\n",
       "      <td>-0.762045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          days  sentiment\n",
       "0  2018-10-05   -1.119873\n",
       "1  2018-10-06   -0.847089\n",
       "2  2018-10-07   -1.485399\n",
       "3  2018-10-08   -0.894346\n",
       "4  2018-10-09   -0.762045"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data\n",
    "sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert days to datetime object\n",
    "\n",
    "sentiment['days'] = pd.to_datetime(sentiment['days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merges sentiment and text data\n",
    "x_y_complete = sentiment.merge(text_day_grouped, how='inner',  left_on='days', right_on='date_grouped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>text_token</th>\n",
       "      <th>date_grouped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>-1.119873</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>['kuala', 'lumpur', 'oct', '4', 'thomson', 're...</td>\n",
       "      <td>2018-10-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-10-06</td>\n",
       "      <td>-0.847089</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>['past', 'couple', 'week', 'see', 'mr.', 'trum...</td>\n",
       "      <td>2018-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-10-07</td>\n",
       "      <td>-1.485399</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>['couple', 'contact', 'december', '2016', 'was...</td>\n",
       "      <td>2018-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>-0.894346</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>['cheltenham', 'england', 'thomson', 'reuters'...</td>\n",
       "      <td>2018-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-10-09</td>\n",
       "      <td>-0.762045</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>['stockholm', 'reuters', 'americans', 'william...</td>\n",
       "      <td>2018-10-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        days  sentiment  year  month  day  \\\n",
       "0 2018-10-05  -1.119873  2018     10    5   \n",
       "1 2018-10-06  -0.847089  2018     10    6   \n",
       "2 2018-10-07  -1.485399  2018     10    7   \n",
       "3 2018-10-08  -0.894346  2018     10    8   \n",
       "4 2018-10-09  -0.762045  2018     10    9   \n",
       "\n",
       "                                          text_token date_grouped  \n",
       "0  ['kuala', 'lumpur', 'oct', '4', 'thomson', 're...   2018-10-05  \n",
       "1  ['past', 'couple', 'week', 'see', 'mr.', 'trum...   2018-10-06  \n",
       "2  ['couple', 'contact', 'december', '2016', 'was...   2018-10-07  \n",
       "3  ['cheltenham', 'england', 'thomson', 'reuters'...   2018-10-08  \n",
       "4  ['stockholm', 'reuters', 'americans', 'william...   2018-10-09  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data\n",
    "x_y_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter datafram\n",
    "x_y = x_y_complete[['days', 'text_token','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>551.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.482033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.419732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.787443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.760585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.515749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-1.239824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.293132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment\n",
       "count  551.000000\n",
       "mean    -1.482033\n",
       "std      0.419732\n",
       "min     -2.787443\n",
       "25%     -1.760585\n",
       "50%     -1.515749\n",
       "75%     -1.239824\n",
       "max      0.293132"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check sentiment distribution\n",
    "x_y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#binarizing sentiment on -1.48 mean value\n",
    "x_y['binary_sentiment'] = np.where(x_y['sentiment'] >= -1.52, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking distribution of targets\n",
    "x_y['binary_sentiment'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days</th>\n",
       "      <th>text_token</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>binary_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>['kuala', 'lumpur', 'oct', '4', 'thomson', 're...</td>\n",
       "      <td>-1.119873</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-10-06</td>\n",
       "      <td>['past', 'couple', 'week', 'see', 'mr.', 'trum...</td>\n",
       "      <td>-0.847089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-10-07</td>\n",
       "      <td>['couple', 'contact', 'december', '2016', 'was...</td>\n",
       "      <td>-1.485399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>['cheltenham', 'england', 'thomson', 'reuters'...</td>\n",
       "      <td>-0.894346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-10-09</td>\n",
       "      <td>['stockholm', 'reuters', 'americans', 'william...</td>\n",
       "      <td>-0.762045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        days                                         text_token  sentiment  \\\n",
       "0 2018-10-05  ['kuala', 'lumpur', 'oct', '4', 'thomson', 're...  -1.119873   \n",
       "1 2018-10-06  ['past', 'couple', 'week', 'see', 'mr.', 'trum...  -0.847089   \n",
       "2 2018-10-07  ['couple', 'contact', 'december', '2016', 'was...  -1.485399   \n",
       "3 2018-10-08  ['cheltenham', 'england', 'thomson', 'reuters'...  -0.894346   \n",
       "4 2018-10-09  ['stockholm', 'reuters', 'americans', 'william...  -0.762045   \n",
       "\n",
       "   binary_sentiment  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data\n",
    "x_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set X, y\n",
    "X = x_y['text_token']\n",
    "y = x_y['binary_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate and fit TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform data\n",
    "X_train = tfidf.transform(X_train)\n",
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(385, 147494)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shape\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 147494)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x147494 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4475 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check object\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net with TF-IDF\n",
    "\n",
    "- Epoch 10/10\n",
    "39/39 [==============================] - 1s 13ms/step - loss: 4.0649 - accuracy: 0.5039 - val_loss: 3.1300 - val_accuracy: 0.5060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert TF-DF sparse to dense matrix\n",
    "X_train = scipy.sparse.csr_matrix.todense(X_train)\n",
    "X_test = scipy.sparse.csr_matrix.todense(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(385, 147494)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define and compile model\n",
    "model = tf.keras.Sequential()\n",
    "#model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "#model.add(text_vectorizer)\n",
    "model.add(tf.keras.layers.Dense(32, input_shape=(X_train.shape[1],), activation='relu', kernel_regularizer=regularizers.l2(.1)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(32, input_shape=(X_train.shape[1],), activation='relu', kernel_regularizer=regularizers.l2(.1)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(y_train.nunique(), activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 32)                4719840   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,720,929\n",
      "Trainable params: 4,720,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 330.0778 - accuracy: 0.4675 - val_loss: 221.0028 - val_accuracy: 0.5060\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 180.0552 - accuracy: 0.5039 - val_loss: 143.1491 - val_accuracy: 0.5060\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 117.3402 - accuracy: 0.5039 - val_loss: 92.9914 - val_accuracy: 0.5060\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 75.7338 - accuracy: 0.5039 - val_loss: 59.4942 - val_accuracy: 0.5060\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 48.0864 - accuracy: 0.5039 - val_loss: 37.4108 - val_accuracy: 0.5060\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 30.0039 - accuracy: 0.4234 - val_loss: 23.1188 - val_accuracy: 0.5060\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 18.4109 - accuracy: 0.5039 - val_loss: 14.0688 - val_accuracy: 0.5060\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 11.1471 - accuracy: 0.5039 - val_loss: 8.4749 - val_accuracy: 0.5060\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 6.7077 - accuracy: 0.5039 - val_loss: 5.1055 - val_accuracy: 0.5060\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 4.0649 - accuracy: 0.5039 - val_loss: 3.1300 - val_accuracy: 0.5060\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "history = model.fit(X_train, y_train, epochs=10, verbose=1, batch_size=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net Regression\n",
    "\n",
    "- Attempts to build model on actual brandwatch sentiment score (as opposed to binarized sentiment)\n",
    "- r-squared: -0.001762950202293334 (horrible :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set new X and Y\n",
    "x_y.head()\n",
    "X= x_y['text_token']\n",
    "y = x_y['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define and compile model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.MeanSquaredError(),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 4s 282ms/step - loss: 9.3297 - val_loss: 8.7471\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 3s 268ms/step - loss: 8.3274 - val_loss: 7.8915\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 3s 267ms/step - loss: 7.5226 - val_loss: 7.1090\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 4s 269ms/step - loss: 6.8061 - val_loss: 6.4474\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 3s 265ms/step - loss: 6.1522 - val_loss: 5.8105\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 3s 269ms/step - loss: 5.5722 - val_loss: 5.2719\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 3s 265ms/step - loss: 5.0324 - val_loss: 4.7673\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 3s 268ms/step - loss: 4.5893 - val_loss: 4.3529\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 3s 266ms/step - loss: 4.1742 - val_loss: 3.9640\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 3s 267ms/step - loss: 3.8055 - val_loss: 3.6157\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 4s 270ms/step - loss: 3.4947 - val_loss: 3.3171\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 3s 267ms/step - loss: 3.1994 - val_loss: 3.0476\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 3s 266ms/step - loss: 2.9428 - val_loss: 2.8034\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 3s 267ms/step - loss: 2.7112 - val_loss: 2.5842\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 3s 265ms/step - loss: 2.4967 - val_loss: 2.3891\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 3s 267ms/step - loss: 2.3170 - val_loss: 2.2120\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 3s 265ms/step - loss: 2.1463 - val_loss: 2.0537\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 3s 269ms/step - loss: 1.9915 - val_loss: 1.9119\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 3s 267ms/step - loss: 1.8561 - val_loss: 1.7819\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 3s 267ms/step - loss: 1.7357 - val_loss: 1.6640\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 4s 272ms/step - loss: 1.6182 - val_loss: 1.5589\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 3s 268ms/step - loss: 1.5119 - val_loss: 1.4594\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 3s 266ms/step - loss: 1.4163 - val_loss: 1.3694\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 3s 265ms/step - loss: 1.3354 - val_loss: 1.2910\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 4s 272ms/step - loss: 1.2800 - val_loss: 1.2340\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 3s 269ms/step - loss: 1.1994 - val_loss: 1.1533\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 4s 308ms/step - loss: 1.1287 - val_loss: 1.0897\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 3s 267ms/step - loss: 1.0644 - val_loss: 1.0294\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 3s 266ms/step - loss: 1.0139 - val_loss: 0.9772\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 4s 272ms/step - loss: 0.9565 - val_loss: 0.9258\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 3s 269ms/step - loss: 0.9053 - val_loss: 0.8796\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 3s 267ms/step - loss: 0.8647 - val_loss: 0.8353\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 3s 267ms/step - loss: 0.8143 - val_loss: 0.7940\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 3s 269ms/step - loss: 0.7785 - val_loss: 0.7571\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 4s 272ms/step - loss: 0.7430 - val_loss: 0.7230\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 4s 273ms/step - loss: 0.7115 - val_loss: 0.6918\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 3s 269ms/step - loss: 0.6768 - val_loss: 0.6620\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 4s 269ms/step - loss: 0.6553 - val_loss: 0.6345\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 3s 266ms/step - loss: 0.6264 - val_loss: 0.6095\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 4s 269ms/step - loss: 0.6024 - val_loss: 0.5855\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 3s 261ms/step - loss: 0.5767 - val_loss: 0.5638\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 3s 266ms/step - loss: 0.5550 - val_loss: 0.5433\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 3s 266ms/step - loss: 0.5348 - val_loss: 0.5251\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 4s 270ms/step - loss: 0.5227 - val_loss: 0.5076\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 3s 269ms/step - loss: 0.4996 - val_loss: 0.4907\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 4s 272ms/step - loss: 0.4907 - val_loss: 0.4771\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 3s 267ms/step - loss: 0.4681 - val_loss: 0.4605\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 3s 268ms/step - loss: 0.4611 - val_loss: 0.4483\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 3s 263ms/step - loss: 0.4481 - val_loss: 0.4353\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 3s 269ms/step - loss: 0.4282 - val_loss: 0.4234\n"
     ]
    }
   ],
   "source": [
    "#fit model\n",
    "history = model.fit(X_train, y_train, epochs=50, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.001762950202293334"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict and calculate r-squared\n",
    "y_pred = model.predict(X_test)\n",
    "r2_score(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "neptune": {
   "notebookId": "95710820-f00d-4aa0-9234-c20b38fb3648"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
